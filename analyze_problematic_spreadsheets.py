#!/usr/bin/env python3
"""
å•é¡Œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ï¼ˆTRUE/SE/ã‚·ãƒ¼ãƒ³ï¼‰ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ§‹é€ è©³ç´°åˆ†æ
"""

import sqlite3
import pandas as pd
import requests
from io import StringIO
import re

def analyze_problematic_spreadsheets():
    db_path = "/Users/mitsuruono/sunsun_script_search/sunsun_script_database/youtube_search_complete_all.db"
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    print("ğŸ” å•é¡Œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ§‹é€ è©³ç´°åˆ†æ")
    print("=" * 80)
    
    # å„å•é¡Œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ä¸Šä½ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç‰¹å®š
    problem_chars = ['TRUE', 'SE', 'ã‚·ãƒ¼ãƒ³']
    
    for char in problem_chars:
        print(f"\nğŸ“Œ {char} ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è©³ç´°åˆ†æ")
        print("=" * 60)
        
        # è©²å½“ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå¤šã„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç‰¹å®š
        cursor.execute("""
            SELECT s.management_id, s.script_url, COUNT(*) as count
            FROM character_dialogue_unified cdu
            JOIN scripts s ON cdu.script_id = s.id
            WHERE cdu.is_instruction = 0 AND cdu.character_name = ?
            GROUP BY s.management_id, s.script_url
            ORDER BY count DESC
            LIMIT 3
        """, (char,))
        
        scripts = cursor.fetchall()
        
        for i, (management_id, script_url, count) in enumerate(scripts, 1):
            print(f"\nğŸ¯ {char}ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸Šä½{i}ä½: {management_id} ({count}ä»¶)")
            print("-" * 50)
            
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®è©³ç´°æ§‹é€ åˆ†æ
            analyze_single_spreadsheet(management_id, script_url, char, cursor)
    
    conn.close()

def analyze_single_spreadsheet(management_id, script_url, focus_char, cursor):
    """å˜ä¸€ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®è©³ç´°æ§‹é€ åˆ†æ"""
    
    # CSV URLã«å¤‰æ›
    csv_url = convert_to_csv_url(script_url)
    print(f"ğŸ“„ URL: {script_url}")
    print(f"ğŸ“„ CSV: {csv_url}")
    
    try:
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå–å¾—
        response = requests.get(csv_url, timeout=30)
        response.raise_for_status()
        
        # UTF-8ã§ãƒ‡ã‚³ãƒ¼ãƒ‰
        csv_content = response.content.decode('utf-8')
        df = pd.read_csv(StringIO(csv_content))
        
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
        print(f"ğŸ“‹ åˆ—å: {list(df.columns)}")
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®æ¤œå‡º
        print(f"\nğŸ” ãƒ˜ãƒƒãƒ€ãƒ¼æ§‹é€ åˆ†æ:")
        for i in range(min(10, len(df))):
            row_preview = []
            for j in range(min(8, len(df.columns))):
                cell_value = str(df.iloc[i, j]) if pd.notna(df.iloc[i, j]) else ""
                cell_short = cell_value[:12] + "..." if len(cell_value) > 12 else cell_value
                row_preview.append(f"[{j}]{cell_short}")
            print(f"  è¡Œ{i+1:2d}: {' | '.join(row_preview)}")
        
        # å•é¡Œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å‡ºç¾ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        print(f"\nğŸ¯ {focus_char}ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å‡ºç¾åˆ†æ:")
        
        # å„åˆ—ã§ã®å‡ºç¾ç¢ºèª
        for col_idx in range(len(df.columns)):
            char_count = df.iloc[:, col_idx].astype(str).str.contains(focus_char, na=False, regex=False).sum()
            if char_count > 0:
                print(f"  åˆ—{col_idx}({df.columns[col_idx]}): {char_count}å›å‡ºç¾")
                
                # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
                char_rows = df[df.iloc[:, col_idx].astype(str).str.contains(focus_char, na=False, regex=False)]
                for idx, row in char_rows.head(3).iterrows():
                    adjacent_cols = []
                    for adj_col in range(max(0, col_idx-1), min(len(df.columns), col_idx+3)):
                        adj_value = str(row.iloc[adj_col]) if pd.notna(row.iloc[adj_col]) else ""
                        adj_short = adj_value[:20] + "..." if len(adj_value) > 20 else adj_value
                        adjacent_cols.append(f"[{adj_col}]{adj_short}")
                    print(f"    è¡Œ{idx+1}: {' | '.join(adjacent_cols)}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã®ç™»éŒ²çŠ¶æ³ã¨æ¯”è¼ƒ
        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç™»éŒ²çŠ¶æ³:")
        cursor.execute("""
            SELECT cdu.character_name, cdu.dialogue_text, cdu.row_number
            FROM character_dialogue_unified cdu
            JOIN scripts s ON cdu.script_id = s.id
            WHERE s.management_id = ? AND cdu.character_name = ?
            ORDER BY cdu.row_number
            LIMIT 5
        """, (management_id, focus_char))
        
        db_samples = cursor.fetchall()
        for char_name, dialogue, row_num in db_samples:
            row_str = f"{row_num:3d}" if row_num is not None else "---"
            dialogue_short = dialogue[:50] + "..." if len(dialogue) > 50 else dialogue
            print(f"  DBè¡Œ{row_str}: {char_name} | \"{dialogue_short}\"")
        
        # æ§‹é€ ã®å•é¡Œç‚¹åˆ†æ
        print(f"\nâš ï¸ æ§‹é€ å•é¡Œã®åˆ†æ:")
        analyze_structure_issues(df, focus_char, management_id)
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def convert_to_csv_url(edit_url):
    """Google Sheetsç·¨é›†URLã‚’CSV URLã«å¤‰æ›"""
    if 'edit#gid=' in edit_url:
        base_url = edit_url.split('/edit#gid=')[0]
        gid = edit_url.split('gid=')[1]
        return f"{base_url}/export?format=csv&gid={gid}"
    else:
        base_url = edit_url.split('/edit')[0]
        return f"{base_url}/export?format=csv&gid=0"

def analyze_structure_issues(df, focus_char, management_id):
    """æ§‹é€ å•é¡Œã®åˆ†æ"""
    
    issues = []
    
    # 1. ãƒ˜ãƒƒãƒ€ãƒ¼ä½ç½®ã®å•é¡Œ
    header_found = False
    for i in range(min(5, len(df))):
        for j in range(len(df.columns)):
            cell_value = str(df.iloc[i, j]).lower()
            if 'ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼' in cell_value or 'character' in cell_value:
                header_found = True
                print(f"  âœ… ãƒ˜ãƒƒãƒ€ãƒ¼ç™ºè¦‹: è¡Œ{i+1}, åˆ—{j+1}")
                break
        if header_found:
            break
    
    if not header_found:
        issues.append("ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒä¸æ˜ç¢º")
    
    # 2. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ—ã®ç‰¹å®š
    main_characters = ['ã‚µãƒ³ã‚µãƒ³', 'ãã‚‚ã‚Šã‚“', 'ãƒ„ã‚¯ãƒ¢', 'ãƒ—ãƒªãƒ«', 'ãƒã‚¤ã‚º']
    char_col_candidates = []
    
    for col_idx in range(len(df.columns)):
        char_score = 0
        for char in main_characters:
            char_score += df.iloc[:, col_idx].astype(str).str.contains(char, na=False).sum()
        if char_score > 0:
            char_col_candidates.append((col_idx, char_score))
    
    char_col_candidates.sort(key=lambda x: x[1], reverse=True)
    
    if char_col_candidates:
        best_char_col = char_col_candidates[0][0]
        print(f"  ğŸ¯ æ¨å®šã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ—: {best_char_col} (ã‚¹ã‚³ã‚¢: {char_col_candidates[0][1]})")
        
        # 3. å•é¡Œã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ—ã«ã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        focus_in_char_col = df.iloc[:, best_char_col].astype(str).str.contains(focus_char, na=False, regex=False).sum()
        print(f"  ğŸ“Š {focus_char}ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ—å‡ºç¾: {focus_in_char_col}å›")
        
        # 4. ã‚»ãƒªãƒ•åˆ—ã®æ¨å®š
        dialogue_col = best_char_col + 1
        if dialogue_col < len(df.columns):
            focus_in_dialogue_col = df.iloc[:, dialogue_col].astype(str).str.contains(focus_char, na=False, regex=False).sum()
            print(f"  ğŸ“Š {focus_char}ã®ã‚»ãƒªãƒ•åˆ—å‡ºç¾: {focus_in_dialogue_col}å›")
            
            if focus_in_dialogue_col > focus_in_char_col:
                issues.append(f"{focus_char}ãŒã‚»ãƒªãƒ•åˆ—ã«å¤šãå‡ºç¾ - åˆ—æ§‹é€ ã®å•é¡Œå¯èƒ½æ€§")
        
        # 5. å®Ÿéš›ã®ã‚»ãƒªãƒ•ã‹ã©ã†ã‹ã®åˆ¤å®š
        if focus_char == 'TRUE':
            analyze_true_character_content(df, best_char_col, dialogue_col)
        elif focus_char == 'SE':
            analyze_se_character_content(df, best_char_col, dialogue_col)
        elif focus_char == 'ã‚·ãƒ¼ãƒ³':
            analyze_scene_character_content(df, best_char_col, dialogue_col)
    
    else:
        issues.append("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ—ãŒç‰¹å®šã§ããªã„")
    
    # å•é¡Œç‚¹ã®ç·æ‹¬
    if issues:
        print(f"  âš ï¸ ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ:")
        for issue in issues:
            print(f"    - {issue}")
    else:
        print(f"  âœ… æ§‹é€ ä¸Šã®æ˜ç¢ºãªå•é¡Œã¯ç™ºè¦‹ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

def analyze_true_character_content(df, char_col, dialogue_col):
    """TRUEã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å†…å®¹åˆ†æ"""
    true_rows = df[df.iloc[:, char_col].astype(str).str.contains('TRUE', na=False, regex=False)]
    
    if len(true_rows) > 0:
        print(f"  ğŸ” TRUEå†…å®¹åˆ†æ ({len(true_rows)}ä»¶):")
        
        # ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çš„å†…å®¹ã‹ã‚»ãƒªãƒ•ã‹ã‚’åˆ¤å®š
        narrative_patterns = [
            r'ã‚€ã‹ã—', r'æ˜”ã€…', r'ã‚ã‚‹æ—¥', r'ãã—ã¦', r'ãã‚Œã‹ã‚‰',
            r'ã§ã—ãŸ', r'ã¾ã—ãŸ', r'ã®ã§ã™', r'^.*ãŸã¡.*',
            r'ç‰©èª', r'ãŠè©±', r'ã¯ã˜ã¾ã‚Š'
        ]
        
        dialogue_patterns = [
            r'[ï¼ï¼Ÿ!?]$', r'^.*[ã ã‚ˆã­]ï¼', r'^.*[ã§ã™]ï¼',
            r'ã€Œ.*ã€', r'ã‚ãƒ¼', r'ã‚„ãƒ¼', r'ãã†'
        ]
        
        narrative_count = 0
        dialogue_count = 0
        
        for _, row in true_rows.head(5).iterrows():
            content = str(row.iloc[dialogue_col]) if pd.notna(row.iloc[dialogue_col]) else ""
            
            is_narrative = any(re.search(pattern, content) for pattern in narrative_patterns)
            is_dialogue = any(re.search(pattern, content) for pattern in dialogue_patterns)
            
            if is_narrative:
                narrative_count += 1
                content_type = "ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"
            elif is_dialogue:
                dialogue_count += 1
                content_type = "ã‚»ãƒªãƒ•"
            else:
                content_type = "ä¸æ˜"
            
            content_short = content[:40] + "..." if len(content) > 40 else content
            print(f"    {content_type}: \"{content_short}\"")
        
        print(f"  ğŸ“Š TRUEå†…å®¹åˆ¤å®š: ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³{narrative_count}ä»¶, ã‚»ãƒªãƒ•{dialogue_count}ä»¶")

def analyze_se_character_content(df, char_col, dialogue_col):
    """SEã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å†…å®¹åˆ†æ"""
    se_rows = df[df.iloc[:, char_col].astype(str).str.contains('SE', na=False, regex=False)]
    
    if len(se_rows) > 0:
        print(f"  ğŸ” SEå†…å®¹åˆ†æ ({len(se_rows)}ä»¶):")
        
        # åŠ¹æœéŸ³æŒ‡ç¤ºã‹ã‚»ãƒªãƒ•ã‹ã‚’åˆ¤å®š
        sound_patterns = [
            r'^\d+$', r'åŠ¹æœéŸ³', r'SE', r'BGM', r'éŸ³',
            r'ãƒ‰ãƒ³', r'ãƒãƒ³', r'ã‚¬ã‚·ãƒ£', r'ãƒ”ãƒ­ãƒªãƒ³'
        ]
        
        dialogue_patterns = [
            r'[ï¼ï¼Ÿ!?]$', r'ã€Œ.*ã€', r'^.*ã¨.*',
            r'ã™ã‚‹', r'ã§ã™', r'ã ', r'ã¾ã™'
        ]
        
        sound_count = 0
        dialogue_count = 0
        
        for _, row in se_rows.head(5).iterrows():
            content = str(row.iloc[dialogue_col]) if pd.notna(row.iloc[dialogue_col]) else ""
            
            is_sound = any(re.search(pattern, content) for pattern in sound_patterns)
            is_dialogue = any(re.search(pattern, content) for pattern in dialogue_patterns)
            
            if is_sound:
                sound_count += 1
                content_type = "åŠ¹æœéŸ³æŒ‡ç¤º"
            elif is_dialogue:
                dialogue_count += 1
                content_type = "ã‚»ãƒªãƒ•/èª¬æ˜"
            else:
                content_type = "ä¸æ˜"
            
            content_short = content[:40] + "..." if len(content) > 40 else content
            print(f"    {content_type}: \"{content_short}\"")
        
        print(f"  ğŸ“Š SEå†…å®¹åˆ¤å®š: åŠ¹æœéŸ³æŒ‡ç¤º{sound_count}ä»¶, ã‚»ãƒªãƒ•/èª¬æ˜{dialogue_count}ä»¶")

def analyze_scene_character_content(df, char_col, dialogue_col):
    """ã‚·ãƒ¼ãƒ³ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®å†…å®¹åˆ†æ"""
    scene_rows = df[df.iloc[:, char_col].astype(str).str.contains('ã‚·ãƒ¼ãƒ³', na=False, regex=False)]
    
    if len(scene_rows) > 0:
        print(f"  ğŸ” ã‚·ãƒ¼ãƒ³å†…å®¹åˆ†æ ({len(scene_rows)}ä»¶):")
        
        # æŠ€è¡“æŒ‡ç¤ºã‹å ´é¢èª¬æ˜ã‹ã‚’åˆ¤å®š
        tech_patterns = [
            r'ãƒ†ãƒ­ãƒƒãƒ—', r'ã‚«ãƒƒãƒˆ', r'ã‚¢ãƒ³ã‚°ãƒ«', r'ã‚ºãƒ¼ãƒ ',
            r'ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ', r'BGM', r'SE', r'ç·¨é›†', r'èª¿æ•´'
        ]
        
        scene_patterns = [
            r'ã™ã‚‹', r'ã§ã‚ã‚‹', r'ã„ã¾ã™', r'ã¾ã—ãŸ',
            r'æ§˜å­', r'çŠ¶æ…‹', r'å§¿', r'è¡¨æƒ…'
        ]
        
        tech_count = 0
        scene_count = 0
        
        for _, row in scene_rows.head(5).iterrows():
            content = str(row.iloc[dialogue_col]) if pd.notna(row.iloc[dialogue_col]) else ""
            
            is_tech = any(re.search(pattern, content) for pattern in tech_patterns)
            is_scene = any(re.search(pattern, content) for pattern in scene_patterns)
            
            if is_tech:
                tech_count += 1
                content_type = "æŠ€è¡“æŒ‡ç¤º"
            elif is_scene:
                scene_count += 1
                content_type = "å ´é¢èª¬æ˜"
            else:
                content_type = "ä¸æ˜"
            
            content_short = content[:40] + "..." if len(content) > 40 else content
            print(f"    {content_type}: \"{content_short}\"")
        
        print(f"  ğŸ“Š ã‚·ãƒ¼ãƒ³å†…å®¹åˆ¤å®š: æŠ€è¡“æŒ‡ç¤º{tech_count}ä»¶, å ´é¢èª¬æ˜{scene_count}ä»¶")

if __name__ == "__main__":
    analyze_problematic_spreadsheets()