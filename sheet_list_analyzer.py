#!/usr/bin/env python3
"""
ã‚·ãƒ¼ãƒˆãƒªã‚¹ãƒˆåˆ†æãƒ„ãƒ¼ãƒ«

ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¨
2019å¹´å°æœ¬ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’åˆ†æã™ã‚‹
"""

import sqlite3
import requests
import pandas as pd
import io
import re
from datetime import datetime

class SheetListAnalyzer:
    def __init__(self, db_path):
        self.db_path = db_path
        self.log_file = "/Users/mitsuruono/sunsun_script_search/sunsun_script_database/sheet_list_analysis.txt"
        
        # æ–°ã—ãæŒ‡å®šã•ã‚ŒãŸã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ
        self.target_sheet = {
            'url': 'https://docs.google.com/spreadsheets/d/1c_txRaInj7yQUFBZLBSj65pLzhKxHofsobLJyM065g8/edit?gid=1092002230#gid=1092002230',
            'name': 'NewSheet'
        }
    
    def log_message(self, message: str):
        """ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {message}\n"
        
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(log_entry)
        
        print(log_entry.strip())
    
    def analyze_sheet_detailed(self, sheet_url, sheet_name):
        """è©³ç´°ãªã‚·ãƒ¼ãƒˆåˆ†æ"""
        try:
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã€GIDæŠ½å‡º
            sheet_pattern = r'/spreadsheets/d/([a-zA-Z0-9-_]+)'
            gid_pattern = r'[#&]gid=([0-9]+)'
            
            sheet_match = re.search(sheet_pattern, sheet_url)
            gid_match = re.search(gid_pattern, sheet_url)
            
            if not sheet_match:
                self.log_message(f"âŒ {sheet_name}: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã‚’æŠ½å‡ºã§ãã¾ã›ã‚“")
                return None
            
            spreadsheet_id = sheet_match.group(1)
            gid = gid_match.group(1) if gid_match else '0'
            
            self.log_message(f"ğŸ“Š {sheet_name}: ID={spreadsheet_id}, GID={gid}")
            
            # CSVå‡ºåŠ›URL
            csv_url = f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/export?format=csv&gid={gid}"
            
            # CSVãƒ‡ãƒ¼ã‚¿å–å¾—
            response = requests.get(csv_url, timeout=15)
            if response.status_code != 200:
                self.log_message(f"âŒ {sheet_name}: HTTP {response.status_code}")
                return None
            
            # CSVè§£æ
            csv_data = response.content.decode('utf-8', errors='ignore')
            df = pd.read_csv(io.StringIO(csv_data))
            
            self.log_message(f"ğŸ“‹ {sheet_name}: {len(df)}è¡Œ x {len(df.columns)}åˆ—")
            
            # æœ€åˆã®15è¡Œã‚’è©³ç´°è¡¨ç¤º
            self.log_message(f"\nğŸ” {sheet_name}: æœ€åˆã®15è¡Œã®å†…å®¹:")
            for row_idx in range(min(15, len(df))):
                row = df.iloc[row_idx]
                row_data = []
                for col_idx, value in enumerate(row):
                    if pd.notna(value):
                        value_str = str(value).strip()
                        if len(value_str) > 0:
                            # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã¯çŸ­ç¸®
                            if len(value_str) > 30:
                                value_str = value_str[:30] + "..."
                            row_data.append(f"åˆ—{col_idx}:'{value_str}'")
                
                if row_data:
                    self.log_message(f"  è¡Œ{row_idx}: {' | '.join(row_data[:6])}")  # æœ€åˆã®6åˆ—ã¾ã§
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼å€™è£œã®è©³ç´°æ¤œç´¢
            header_candidates = {
                'character': [],
                'dialogue': [],
                'filming': [],
                'audio': [],
                'other': []
            }
            
            for row_idx in range(min(20, len(df))):
                row = df.iloc[row_idx]
                for col_idx, value in enumerate(row):
                    if pd.notna(value):
                        value_str = str(value).strip().lower()
                        original_str = str(value).strip()
                        
                        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ˜ãƒƒãƒ€ãƒ¼å€™è£œ
                        char_keywords = ['ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼', 'ã‚­ãƒ£ãƒ©', 'character', 'è©±è€…', 'ç™»å ´äººç‰©', 'ç™»å ´ã‚­ãƒ£ãƒ©']
                        if any(keyword in value_str for keyword in char_keywords):
                            header_candidates['character'].append({
                                'row': row_idx, 'col': col_idx, 'text': original_str
                            })
                        
                        # ã‚»ãƒªãƒ•ãƒ˜ãƒƒãƒ€ãƒ¼å€™è£œ
                        dialogue_keywords = ['ã‚»ãƒªãƒ•', 'ã›ã‚Šãµ', 'dialogue', 'ãƒ€ã‚¤ã‚¢ãƒ­ã‚°', 'ç™ºè¨€', 'å°è©']
                        if any(keyword in value_str for keyword in dialogue_keywords):
                            header_candidates['dialogue'].append({
                                'row': row_idx, 'col': col_idx, 'text': original_str
                            })
                        
                        # æ’®å½±æŒ‡ç¤ºãƒ˜ãƒƒãƒ€ãƒ¼å€™è£œ
                        filming_keywords = ['æ’®å½±æŒ‡ç¤º', 'æ’®å½±', 'filming', 'æ˜ åƒæŒ‡ç¤º', 'æ˜ åƒ']
                        if any(keyword in value_str for keyword in filming_keywords):
                            header_candidates['filming'].append({
                                'row': row_idx, 'col': col_idx, 'text': original_str
                            })
                        
                        # éŸ³å£°æŒ‡ç¤ºãƒ˜ãƒƒãƒ€ãƒ¼å€™è£œ
                        audio_keywords = ['éŸ³å£°æŒ‡ç¤º', 'éŸ³å£°', 'audio', 'åŠ¹æœéŸ³']
                        if any(keyword in value_str for keyword in audio_keywords):
                            header_candidates['audio'].append({
                                'row': row_idx, 'col': col_idx, 'text': original_str
                            })
                        
                        # ãã®ä»–ã®èˆˆå‘³æ·±ã„ãƒ˜ãƒƒãƒ€ãƒ¼
                        other_keywords = ['no.', 'no', 'ç•ªå·', 'ã‚¿ã‚¤ãƒˆãƒ«', 'title', 'æ™‚é–“', 'time']
                        if any(keyword in value_str for keyword in other_keywords):
                            header_candidates['other'].append({
                                'row': row_idx, 'col': col_idx, 'text': original_str
                            })
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼å€™è£œã®å ±å‘Š
            self.log_message(f"\nğŸ“ {sheet_name}: ãƒ˜ãƒƒãƒ€ãƒ¼å€™è£œè©³ç´°:")
            for header_type, candidates in header_candidates.items():
                if candidates:
                    self.log_message(f"  {header_type}: {len(candidates)}å€‹")
                    for candidate in candidates:
                        self.log_message(f"    è¡Œ{candidate['row']}åˆ—{candidate['col']}: '{candidate['text']}'")
                else:
                    self.log_message(f"  {header_type}: è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            # æ½œåœ¨çš„ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã®æ¤œç´¢
            potential_characters = set()
            known_characters = {
                'ã‚µãƒ³ã‚µãƒ³', 'ãã‚‚ã‚Šã‚“', 'ãƒ„ã‚¯ãƒ¢', 'ãƒã‚¤ã‚º', 'BB', 'ãƒ—ãƒªãƒ«', 
                'ã‚«ã‚¨ãƒ«ãƒ³', 'ã‚¦ã‚µãƒƒãƒ', 'ãƒ¢ãƒ¼ãƒ¬ãƒ„å…ˆç”Ÿ', 'ããƒ¼ã ãŠã˜ã•ã‚“'
            }
            
            for row_idx in range(len(df)):
                row = df.iloc[row_idx]
                for col_idx, value in enumerate(row):
                    if pd.notna(value):
                        value_str = str(value).strip()
                        if value_str in known_characters:
                            potential_characters.add(value_str)
            
            if potential_characters:
                self.log_message(f"\nğŸ­ {sheet_name}: ç™ºè¦‹ã•ã‚ŒãŸæ—¢çŸ¥ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼:")
                for char in sorted(potential_characters):
                    self.log_message(f"  - {char}")
            else:
                self.log_message(f"\nğŸ­ {sheet_name}: æ—¢çŸ¥ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            return {
                'sheet_name': sheet_name,
                'total_rows': len(df),
                'total_cols': len(df.columns),
                'header_candidates': header_candidates,
                'potential_characters': potential_characters,
                'dataframe': df
            }
            
        except Exception as e:
            self.log_message(f"âŒ {sheet_name}: åˆ†æã‚¨ãƒ©ãƒ¼ - {str(e)}")
            return None
    
    def check_2019_data_in_database(self):
        """2019å¹´ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # 2019å¹´ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ¤œç´¢
            cursor.execute("""
                SELECT s.management_id, s.title, s.script_url,
                       COUNT(cdu.id) as character_count
                FROM scripts s
                LEFT JOIN character_dialogue_unified cdu ON s.id = cdu.script_id
                WHERE s.management_id LIKE '%2019%' 
                   OR s.title LIKE '%2019%'
                   OR s.management_id LIKE 'A%'
                GROUP BY s.id, s.management_id, s.title, s.script_url
                ORDER BY s.management_id
                LIMIT 20
            """)
            
            results = cursor.fetchall()
            conn.close()
            
            self.log_message("\nğŸ—“ï¸ 2019å¹´é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³:")
            if results:
                for mgmt_id, title, script_url, char_count in results:
                    self.log_message(f"  {mgmt_id}: {char_count}ä»¶ - {title[:50]}...")
                    if script_url:
                        self.log_message(f"    URL: {script_url[:80]}...")
            else:
                self.log_message("  âŒ 2019å¹´é–¢é€£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            return results
            
        except Exception as e:
            self.log_message(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def run_comprehensive_analysis(self):
        """åŒ…æ‹¬çš„åˆ†æå®Ÿè¡Œ"""
        self.log_message("=" * 80)
        self.log_message("æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¨2019å¹´ãƒ‡ãƒ¼ã‚¿ã®åŒ…æ‹¬åˆ†æé–‹å§‹")
        self.log_message("=" * 80)
        
        # æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åˆ†æ
        self.log_message(f"\n{'=' * 60}")
        self.log_message(f"æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆåˆ†æ")
        self.log_message(f"URL: {self.target_sheet['url']}")
        self.log_message(f"{'=' * 60}")
        
        new_sheet_analysis = self.analyze_sheet_detailed(
            self.target_sheet['url'], 
            self.target_sheet['name']
        )
        
        # 2019å¹´ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        self.log_message(f"\n{'=' * 60}")
        self.log_message(f"2019å¹´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèª")
        self.log_message(f"{'=' * 60}")
        
        db_2019_results = self.check_2019_data_in_database()
        
        # ç·åˆåˆ¤å®š
        self.log_message("\n" + "=" * 80)
        self.log_message("ç·åˆåˆ†æçµæœ")
        self.log_message("=" * 80)
        
        if new_sheet_analysis:
            char_headers = len(new_sheet_analysis['header_candidates']['character'])
            dialogue_headers = len(new_sheet_analysis['header_candidates']['dialogue'])
            potential_chars = len(new_sheet_analysis['potential_characters'])
            
            self.log_message(f"ğŸ“Š æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ:")
            self.log_message(f"  ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒ˜ãƒƒãƒ€ãƒ¼: {char_headers}å€‹")
            self.log_message(f"  ã‚»ãƒªãƒ•ãƒ˜ãƒƒãƒ€ãƒ¼: {dialogue_headers}å€‹")
            self.log_message(f"  ç™ºè¦‹ã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼: {potential_chars}å€‹")
            
            if char_headers == 0 or dialogue_headers == 0:
                self.log_message(f"  âš ï¸  ã“ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¯æŠ½å‡ºãŒå›°é›£ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            else:
                self.log_message(f"  âœ… ã“ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¯æŠ½å‡ºå¯èƒ½ã¨æ€ã‚ã‚Œã¾ã™")
        
        self.log_message(f"ğŸ“Š 2019å¹´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹:")
        self.log_message(f"  ç™ºè¦‹ã•ã‚ŒãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆ: {len(db_2019_results)}å€‹")
        
        if db_2019_results:
            low_char_count = sum(1 for _, _, _, count in db_2019_results if count < 10)
            if low_char_count > len(db_2019_results) * 0.5:
                self.log_message(f"  âš ï¸  å¤šãã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æ•°ãŒå°‘ãªãã€æŠ½å‡ºä¸å‚™ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            else:
                self.log_message(f"  âœ… å¤šãã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§é©åˆ‡ã«ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒæŠ½å‡ºã•ã‚Œã¦ã„ã¾ã™")
        
        self.log_message("=" * 80)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    db_path = "/Users/mitsuruono/sunsun_script_search/sunsun_script_database/youtube_search_complete_all.db"
    
    analyzer = SheetListAnalyzer(db_path)
    
    print("=== ã‚·ãƒ¼ãƒˆãƒªã‚¹ãƒˆåˆ†æãƒ„ãƒ¼ãƒ« ===")
    
    # åŒ…æ‹¬åˆ†æå®Ÿè¡Œ
    analyzer.run_comprehensive_analysis()
    
    print(f"\nâœ… åˆ†æå®Œäº†ï¼")
    print(f"è©³ç´°ã¯ sheet_list_analysis.txt ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()